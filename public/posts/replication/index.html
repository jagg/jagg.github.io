<!doctype html>

<html lang="en-us">

<head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script>
  <title>Adding replication to the Key-Value Store - Logos, Thumos &amp; Code</title>
  <meta charset="utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<meta name="description" content="Random ideas about programming" />
<meta name="author" content="Jose A. Garcia" /><meta property="og:url" content="http://localhost:1313/posts/replication/">
  <meta property="og:site_name" content="Logos, Thumos & Code">
  <meta property="og:title" content="Adding replication to the Key-Value Store">
  <meta property="og:description" content="During the past few weeks I’ve built a basic key-value store that persists data to disk. It works, but only as a single node, so there is a fixed limit on the amount of data it can store, and the througput it can sustain.
We can make the store scale horizontally in two ways:
Replication, which keeps additional copies of the data in other nodes, improving throughput. Sharding, which partitions the keys across different nodes, so that we can store more data. In this post I’m going to tackle the first one, replication, refactoring the storage layer so that we can have as many replicas as we want serving reads. All the code is available in GitHub.">
  <meta property="og:locale" content="en_us">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2025-04-18T19:43:07+02:00">
    <meta property="article:modified_time" content="2025-04-18T19:43:07+02:00">
    <meta property="article:tag" content="Databases">
    <meta property="og:image" content="http://localhost:1313/">


  <meta name="twitter:card" content="summary_large_image">
  <meta name="twitter:image" content="http://localhost:1313/">
  <meta name="twitter:title" content="Adding replication to the Key-Value Store">
  <meta name="twitter:description" content="During the past few weeks I’ve built a basic key-value store that persists data to disk. It works, but only as a single node, so there is a fixed limit on the amount of data it can store, and the througput it can sustain.
We can make the store scale horizontally in two ways:
Replication, which keeps additional copies of the data in other nodes, improving throughput. Sharding, which partitions the keys across different nodes, so that we can store more data. In this post I’m going to tackle the first one, replication, refactoring the storage layer so that we can have as many replicas as we want serving reads. All the code is available in GitHub.">

<meta name="generator" content="Hugo 0.146.5">
    
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script src="http://localhost:1313/js/mathjax-config.js" defer></script>
    <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>

  <link rel="stylesheet" href="http://localhost:1313/css/normalize.min.css" />
  <link rel="stylesheet" href="http://localhost:1313/fontawesome/css/all.min.css" />
  
    <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto+Slab|Ruda" />
  
  
  <link rel="stylesheet" type="text/css" href="http://localhost:1313/css/styles.css" />
</head>

<body>
  <div id="container">
    <header>
      
      <h1>
        <a href="http://localhost:1313/">Logos, Thumos &amp; Code</a>
      </h1>

      <ul id="social-media">
             <li>
               <a href="https://github.com/jagg" title="GitHub">
               <i class="fab fa-github fa-lg"></i>
               </a>
             </li>
             <li>
               <a href="https://twitter.com/jagarciagim" title="Twitter">
               <i class="fab fa-twitter fa-lg"></i>
               </a>
             </li>
      </ul>
      
      <p><em>Let&rsquo;s write some code</em></p>
      
    </header>

    
<nav>
    <ul>
        
        <li>
            <a class="" href="http://localhost:1313/categories">
                <i class="fa-li fa  fa-lg"></i><span>Categories</span>
            </a>
        </li>
        
        <li>
            <a class="" href="http://localhost:1313/tags">
                <i class="fa-li fa  fa-lg"></i><span>Tags</span>
            </a>
        </li>
        
    </ul>
</nav>


    <main>




<article>

    <h1>Adding replication to the Key-Value Store</h1>

    
      <aside>
    <ul>
        <li>
            <time class="post-date" datetime="2025-04-18T19:43:07&#43;02:00">Apr 18, 2025</time>
        </li>
        
        
        <li>
            Categories:
            <em>
                
                    
                    <a href="http://localhost:1313/categories/ocaml">OCaml</a>
                
            </em>
        </li>
        

        
        <li>
            <em>
                
                    
                    <a href="http://localhost:1313/tags/databases">#databases</a>
                
            </em>
        </li>
        

        <li>6 minute read</li>
    </ul>
</aside>

    

    
      
<div class="featured_image">
    <a href="http://localhost:1313/posts/replication/" title="Adding replication to the Key-Value Store">
        <img src="">
    </a>
</div>


    

    <p>During the past few weeks I&rsquo;ve built a basic key-value store that
persists data to disk. It works, but only as a single node, so there
is a fixed limit on the amount of data it can store, and the througput
it can sustain.</p>
<p>We can make the store scale horizontally in two ways:</p>
<ul>
<li><strong>Replication</strong>, which keeps additional copies of the data in other nodes, improving
throughput.</li>
<li><strong>Sharding</strong>, which partitions the keys across different nodes, so that we can store more data.</li>
</ul>
<p>In this post I&rsquo;m going to tackle the first one, replication,
refactoring the storage layer so that we can have as many replicas as
we want serving reads. All the code is available in
<a href="https://github.com/jagg/ocledis">GitHub</a>.</p>
<h1 id="why-replication">Why Replication?</h1>
<p>Any modern database these days will keep an additional copy of the data
on a different server. That has a couple of advantages:</p>
<ul>
<li>
<p>If the original server dies, the other one can take its place and
answer queries.</p>
</li>
<li>
<p>If you have the data in multiple servers, clients can call any of
them, so now you have several times the original read throughput!</p>
</li>
</ul>
<p>This also comes with downsides. If you have replicas, now the store is
distributed, and that comes with a lot of added complexity and failure
modes. You have to decide how to handle writes, and what happens when
different nodes disagree about the current state of the system.</p>
<h2 id="alternatives">Alternatives</h2>
<p>There are usually three approaches:</p>
<ol>
<li>
<p>Single Leader replication: One leader is configured as the leader,
and it&rsquo;s the only one that can process writes. It then sends the
data to the followers. Both leader and followers can process read
operations.</p>
</li>
<li>
<p>Multi-leader replication: Same as above, but now you have more than
one replica processing write operations. It&rsquo;s usually done to
replicate data across data centres. You can configure one leader
per data centre, the leader will send updates to the local
replicas, and then send it over the internet to the leader of the
other data centre.</p>
</li>
<li>
<p>Leaderless replication: This is the other extreme, any node can
accept write operations. This one requires consensus algorithms to
decide what to do when two concurrent writes across different nodes
try to write to the same key.</p>
</li>
</ol>
<p>All of this is really well explained in the &ldquo;Designing Data-Intensive
Applications&rdquo; book, by Martin Kleppmann, I really recommend it!.</p>
<h2 id="single-leader-replication">Single Leader Replication</h2>
<p>In my Key-Value store I&rsquo;m implementing the &ldquo;simplest&rdquo; approach for
now. Only one leader in the cluster, and it is pre-configured. What
happens if the leader dies? Ideally we would implement a leader
election algorithm to pick another one. For now my implementation just
stops accepting writes.</p>
<p>Even if we only limit the system to have one writer, we still can have
consistency problems. Since sending updates to the follower replicas
takes time, they can fall behind. It&rsquo;s possible for a client to write
an update to a key, then try to read it from a different replica, and
get the old value. Using this scheme the store can only be &ldquo;eventually
consistent&rdquo;. A way to mitigate this issue is to call the leader to
read data that we updated recently.</p>
<p>At the very least we will want to make sure that each client reads
from the same replica to ensure that the data is internally
consistent and doesn&rsquo;t go back in time (you could get a value from an
up to date replica, then read it again from a replica falling behind,
and get an older value, not the one that was last written).</p>
<h1 id="implementation">Implementation</h1>
<p>Before writing this I took the chance to do some refactoring. I split
the storage layer into disk &amp; memory storage, with a store module to
coordinate them. Then, adding a replication layer was easier.</p>
<p><img src="http://localhost:1313/posts/replication.png" alt="Store architecture"></p>
<h2 id="the-store-coordinator">The Store coordinator</h2>
<p>Now each server node can operate on two different modes, as a Leader,
or a Follower. It also needs some configuration, so that it can find
the replicas, and it also needs to know where to store the WAL, and
the disk checkpoint (see previous <a href="http://localhost:1313/posts/wal/">post</a>).</p>
<p>Also, update operations now need network access. This complicates a
bit the signature of the function, since now we need to take the Eio
Switch, and the network token.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-ocaml" data-lang="ocaml"><span style="display:flex;"><span><span style="color:#66d9ef">open</span><span style="color:#f92672">!</span> <span style="color:#a6e22e">Base</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">type</span> t
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">type</span> mode <span style="color:#f92672">=</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">|</span> <span style="color:#a6e22e">Leader</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">|</span> <span style="color:#a6e22e">Follower</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">[@@</span>deriving sexp<span style="color:#f92672">]</span>
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">type</span> config <span style="color:#f92672">=</span> <span style="color:#f92672">{</span>
</span></span><span style="display:flex;"><span>  replica <span style="color:#f92672">:</span> Replica_store.replica_config<span style="color:#f92672">;</span>
</span></span><span style="display:flex;"><span>  disk <span style="color:#f92672">:</span> Disk_store.disk_config<span style="color:#f92672">;</span>
</span></span><span style="display:flex;"><span>  mode <span style="color:#f92672">:</span> mode<span style="color:#f92672">;</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">}</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">[@@</span>deriving sexp<span style="color:#f92672">]</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">val</span> make <span style="color:#f92672">:</span> config <span style="color:#f92672">-&gt;</span> t
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">val</span> update <span style="color:#f92672">:</span> t <span style="color:#f92672">-&gt;</span> Model.update_op <span style="color:#f92672">-&gt;</span> Eio.Switch.t <span style="color:#f92672">-&gt;</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">[&gt;</span> <span style="color:#f92672">[&gt;</span> <span style="color:#f92672">`</span><span style="color:#a6e22e">Generic</span> <span style="color:#f92672">]</span> Eio.Net.ty <span style="color:#f92672">]</span> Eio.Resource.t <span style="color:#f92672">-&gt;</span>
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">unit</span> Or_error.t
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">val</span> get <span style="color:#f92672">:</span> t <span style="color:#f92672">-&gt;</span> Model.Key.t <span style="color:#f92672">-&gt;</span> Model.value option
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">val</span> default_config <span style="color:#f92672">:</span> config
</span></span></code></pre></div><p>An update needs to:</p>
<ol>
<li>Store the update operation in the WAL</li>
<li>If the node is the leader, it needs to propagate it to the replicas</li>
<li>Store the date in memory</li>
<li>Consider if a checkpoint is required</li>
</ol>
<p>If any of this operations fails we return an error to the client. We
can model that with Or_error, using the <code>bind</code> (&raquo;=) operator (monads!).</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-ocaml" data-lang="ocaml"><span style="display:flex;"><span><span style="color:#66d9ef">let</span> update store op sw net <span style="color:#f92672">=</span>
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">let</span> <span style="color:#66d9ef">open</span> <span style="color:#a6e22e">Or_error</span> <span style="color:#66d9ef">in</span>
</span></span><span style="display:flex;"><span>  Disk_store.process store<span style="color:#f92672">.</span>disk op
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">&gt;&gt;=</span> <span style="color:#66d9ef">fun</span> () <span style="color:#f92672">-&gt;</span> <span style="color:#66d9ef">match</span> store<span style="color:#f92672">.</span>config<span style="color:#f92672">.</span>mode <span style="color:#66d9ef">with</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">|</span> <span style="color:#a6e22e">Leader</span> <span style="color:#f92672">-&gt;</span> Replica_store.update store<span style="color:#f92672">.</span>repl op sw net
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">|</span> <span style="color:#a6e22e">Follower</span> <span style="color:#f92672">-&gt;</span> <span style="color:#a6e22e">Ok</span> ()
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">&gt;&gt;=</span> <span style="color:#66d9ef">fun</span> () <span style="color:#f92672">-&gt;</span>
</span></span><span style="display:flex;"><span>  Memory_store.update store<span style="color:#f92672">.</span>mem op<span style="color:#f92672">;</span>
</span></span><span style="display:flex;"><span>  <span style="color:#a6e22e">Ok</span> ()
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">&gt;&gt;=</span> <span style="color:#66d9ef">fun</span> () <span style="color:#f92672">-&gt;</span>
</span></span><span style="display:flex;"><span>  store<span style="color:#f92672">.</span>op_count <span style="color:#f92672">&lt;-</span> store<span style="color:#f92672">.</span>op_count <span style="color:#f92672">+</span> 1<span style="color:#f92672">;</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">(</span><span style="color:#66d9ef">if</span> store<span style="color:#f92672">.</span>op_count <span style="color:#f92672">&gt;</span> 5 <span style="color:#66d9ef">then</span>
</span></span><span style="display:flex;"><span>     <span style="color:#66d9ef">let</span> () <span style="color:#f92672">=</span> store<span style="color:#f92672">.</span>op_count <span style="color:#f92672">&lt;-</span> 0 <span style="color:#66d9ef">in</span>
</span></span><span style="display:flex;"><span>     Disk_store.checkpoint store<span style="color:#f92672">.</span>disk store<span style="color:#f92672">.</span>mem
</span></span><span style="display:flex;"><span>   <span style="color:#66d9ef">else</span>
</span></span><span style="display:flex;"><span>     <span style="color:#a6e22e">Ok</span> ()<span style="color:#f92672">)</span> 
</span></span></code></pre></div><p>Thanks to <code>bind</code> we can chain functions that return <code>Or_error.t</code>, and
as soon as one of them is an Error, the execution is aborted,
returning it. It saves us the time of having to check each result
individually.</p>
<p>The code above is trigering a checkpoint every 5 operations. Usually
this value would be a lot higher, but I&rsquo;m using a low number so that I
can see it working.</p>
<p>Also, you may have noticed that there is nothing here keeping
followers from accepting write operations! That&rsquo;s correct, it&rsquo;s in my
TODO list. It should accept updates only from the accepted leader, and
reject the rest.</p>
<h2 id="the-replication-layer">The Replication layer</h2>
<p>There isn&rsquo;t much to it, just iterate over the replicas sending the
updates. Ideally we could send the updates in parallel, and maybe stop
waiting after n replicas acknowledge the change, but for now I&rsquo;m
keeping the code simple.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-ocaml" data-lang="ocaml"><span style="display:flex;"><span><span style="color:#66d9ef">let</span> update replica op sw net <span style="color:#f92672">=</span>
</span></span><span style="display:flex;"><span>  Or_error.try_with <span style="color:#f92672">@@</span> <span style="color:#66d9ef">fun</span> () <span style="color:#f92672">-&gt;</span>
</span></span><span style="display:flex;"><span>  List.iter replica<span style="color:#f92672">.</span>config<span style="color:#f92672">.</span>replicas <span style="color:#f92672">~</span>f<span style="color:#f92672">:(</span><span style="color:#66d9ef">fun</span> <span style="color:#f92672">(</span>ip<span style="color:#f92672">,</span> port<span style="color:#f92672">)</span> <span style="color:#f92672">-&gt;</span>
</span></span><span style="display:flex;"><span>      <span style="color:#66d9ef">let</span> ipp <span style="color:#f92672">=</span> Unix.inet_addr_of_string ip <span style="color:#66d9ef">in</span>
</span></span><span style="display:flex;"><span>      <span style="color:#66d9ef">let</span> ipv4 <span style="color:#f92672">=</span> Eio_unix.Net.Ipaddr.of_unix ipp <span style="color:#66d9ef">in</span>
</span></span><span style="display:flex;"><span>      <span style="color:#66d9ef">let</span> addr <span style="color:#f92672">=</span> <span style="color:#f92672">`</span><span style="color:#a6e22e">Tcp</span> <span style="color:#f92672">(</span>ipv4<span style="color:#f92672">,</span> port<span style="color:#f92672">)</span> <span style="color:#66d9ef">in</span>
</span></span><span style="display:flex;"><span>      <span style="color:#66d9ef">let</span> flow <span style="color:#f92672">=</span> Eio.Net.connect <span style="color:#f92672">~</span>sw net addr <span style="color:#66d9ef">in</span>
</span></span><span style="display:flex;"><span>      <span style="color:#66d9ef">let</span> <span style="color:#66d9ef">open</span> <span style="color:#a6e22e">Protocol</span> <span style="color:#66d9ef">in</span>
</span></span><span style="display:flex;"><span>      <span style="color:#66d9ef">let</span> command <span style="color:#f92672">=</span> to_command op <span style="color:#66d9ef">in</span>
</span></span><span style="display:flex;"><span>      Eio.Buf_write.with_flow flow <span style="color:#f92672">@@</span> <span style="color:#66d9ef">fun</span> to_server <span style="color:#f92672">-&gt;</span>
</span></span><span style="display:flex;"><span>      send_commands <span style="color:#f92672">[</span>command<span style="color:#f92672">]</span> to_server
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">)</span>
</span></span></code></pre></div><h1 id="next-steps">Next steps</h1>
<p>Now we have a single-leader replication scheme for the key-value store
that can scale its read throughput horizontally by adding more
replicas, but there is still a lot to do:</p>
<ol>
<li>Ensure that the followers only accept updates from the leader.</li>
<li>Benchmark replication latency, and improve performance.</li>
<li>Implement a leader election algorithm, maybe Raft.</li>
<li>Scale storage through sharding, partitioning keys across nodes.</li>
</ol>
<p>What we have today is a basic skeleton that can be used to experiment
with more complex algorithms. Things are getting interesting!</p>
<p>All the code is available <a href="https://github.com/jagg/ocledis">here</a>. If
you came this far I would love to here you comments and feedback. You
can find me on <a href="https://x.com/jagarciagim">X / Twitter</a>!</p>


</article>


<section class="post-nav">
    <ul>
        <li>
        
            <a href="http://localhost:1313/posts/eio/"><i class="fa fa-chevron-circle-left"></i> Notes on Eio</a>
        
        </li>
        <li>
        
        </li>
    </ul>
</section>
  
    
    
  





</main>
    <footer>
        <ul>
            <li>
                <h6>Copyright © 2025 - Jose A. Garcia | 
                    Rendered by <a href="https://gohugo.io" title="Hugo">Hugo</a> |
                    <a href="http://localhost:1313/index.xml">Subscribe </a></h6>
            </li>
            
            
        </ul>
    </footer>
</div>
<script src="http://localhost:1313/js/scripts.js"></script>

  


</body>

</html>

